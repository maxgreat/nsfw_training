{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Variables\n",
    "MEAN_PREPRO = [0.485, 0.456, 0.406]\n",
    "STD_PREPRO = [0.229, 0.224, 0.225]\n",
    "RESIZE_PREPRO = 256,256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TRAIN_SHUFFLE = True\n",
    "TRAIN_NUM_WORKERS = 8\n",
    "TRAIN_PIN_MEMORY = True\n",
    "\n",
    "VAL_BATCH_SIZE = 512\n",
    "VAL_SHUFFLE = False\n",
    "VAL_NUM_WORKERS = 4\n",
    "VAL_PIN_MEMORY = True\n",
    "\n",
    "INITIAL_LR = 1e-4\n",
    "DEVICE_ID = 1\n",
    "\n",
    "DATA_DIR = '/data/porn/data'\n",
    "TRAINSET_ROOT = f'{DATA_DIR}/train'\n",
    "TESTSET_ROOT = f'{DATA_DIR}/test'\n",
    "\n",
    "TENSORBOARD_DIR = '/data/porn/tensorboard/resnet50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=MEAN_PREPRO, std=STD_PREPRO\n",
    "    )\n",
    "prepro = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "prepro_val = transforms.Compose(\n",
    "    [transforms.Resize(RESIZE_PREPRO), transforms.ToTensor(), normalize]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(TRAINSET_ROOT, transform=prepro)\n",
    "val_dataset = ImageFolder(TESTSET_ROOT, transform=prepro_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 183019\n",
      "    Root location: /data/porn/data/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(256, 256), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['drawings', 'hentai', 'neutral', 'porn']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=TRAIN_SHUFFLE, num_workers=TRAIN_NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=VAL_SHUFFLE, num_workers=VAL_NUM_WORKERS, pin_memory=VAL_PIN_MEMORY, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(2048, len(train_dataset.classes))\n",
    "DEVICE = f\"cuda:{DEVICE_ID}\"\n",
    "model = model.to(DEVICE)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=INITIAL_LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(classes, cm):\n",
    "    fig, ax = plt.subplots(figsize=(len(classes),len(classes)))  \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax,fmt=\"d\")\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels') \n",
    "    ax.set_title('Confusion Matrix') \n",
    "    ax.xaxis.set_ticklabels(classes,rotation=90)\n",
    "    ax.yaxis.set_ticklabels(classes,rotation=0)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    on_iteration=None,\n",
    "):\n",
    "    model = model.train()\n",
    "    end = time.time()\n",
    "    print(\"Start Training\")\n",
    "    avg_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        print(f\"{i/len(train_loader) * 100 : 2.2f}%\", end=\"\\r\")\n",
    "        iteration_time = time.time()\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        avg_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if on_iteration is not None:\n",
    "            on_iteration(iteration=i+epoch*len(train_loader), loss=loss, y_pred=outputs, y_true=labels)     \n",
    "    return avg_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, \n",
    "             model, \n",
    "             criterion,\n",
    "             print_freq=1000):\n",
    "    model = model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "    avg_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(val_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            avg_loss += criterion(outputs, labels).item()\n",
    "        _, indices = torch.max(outputs.cpu(), 1)\n",
    "        y_pred.append(indices)\n",
    "        y_true.append(labels.cpu().clone())\n",
    "    return avg_loss/len(val_loader), torch.cat(y_pred), torch.cat(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_porn_detection(epoch, y_pred, y_true):\n",
    "    ones = torch.ones(len(y_pred))\n",
    "    p_pred = (y_pred == 1) | (y_pred == 3)\n",
    "    p_truth = (y_true == 1) | (y_true == 3)\n",
    "    logger.add_pr_curve(\"Eval/Prec_recall\", p_truth, p_pred, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_logs(epoch, loss_avg, y_pred, y_true):\n",
    "    logger.add_scalar(\"Loss/Avg_Val\", loss_avg, epoch)\n",
    "    logger.add_scalar(\"Eval/Precision\", (y_pred==y_true).sum()/float(len(y_pred)), epoch)\n",
    "    compute_porn_detection(epoch, y_pred, y_true)\n",
    "    cm = confusion_matrix(y_pred, y_true)\n",
    "    cm_image = plot_cm(train_dataset.classes, cm)\n",
    "    logger.add_figure(\"Eval/Confusion Matrix\", cm_image, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_iteration_logs(iteration, loss, y_pred, y_true):\n",
    "    l = loss.item()\n",
    "    if iteration%50 == 0:\n",
    "        logger.add_scalar(\"Loss/Train\", l, iteration)\n",
    "        print(\n",
    "                f\"{iteration}/{len(train_loader)} \\t\"\n",
    "                f\"Loss {l}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(TENSORBOARD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "0/1429 \tLoss 1.645801305770874\n",
      "50/1429 \tLoss 0.8847590684890747\n",
      "100/1429 \tLoss 0.7891713380813599\n",
      "150/1429 \tLoss 0.7394140958786011\n",
      "200/1429 \tLoss 0.5289117693901062\n",
      "250/1429 \tLoss 0.4995679259300232\n",
      "300/1429 \tLoss 0.4629546105861664\n",
      "350/1429 \tLoss 0.5019838213920593\n",
      "400/1429 \tLoss 0.47636640071868896\n",
      "450/1429 \tLoss 0.48804357647895813\n",
      "500/1429 \tLoss 0.40514490008354187\n",
      "550/1429 \tLoss 0.39292454719543457\n",
      "600/1429 \tLoss 0.35952550172805786\n",
      "650/1429 \tLoss 0.4427937865257263\n",
      "700/1429 \tLoss 0.4801381826400757\n",
      "750/1429 \tLoss 0.4111124277114868\n",
      "800/1429 \tLoss 0.3206721246242523\n",
      "850/1429 \tLoss 0.41951197385787964\n",
      "900/1429 \tLoss 0.4607880115509033\n",
      "950/1429 \tLoss 0.3891167938709259\n",
      "1000/1429 \tLoss 0.3584074378013611\n",
      "1050/1429 \tLoss 0.38679301738739014\n",
      "1100/1429 \tLoss 0.36941391229629517\n",
      "1150/1429 \tLoss 0.3034724295139313\n",
      "1200/1429 \tLoss 0.39026010036468506\n",
      "1250/1429 \tLoss 0.29458874464035034\n",
      "1300/1429 \tLoss 0.3645346462726593\n",
      "1350/1429 \tLoss 0.4596782624721527\n",
      "1400/1429 \tLoss 0.4195210337638855\n",
      "Start Training\n",
      "1450/1429 \tLoss 0.2728012800216675\n",
      "1500/1429 \tLoss 0.2736804783344269\n",
      "1550/1429 \tLoss 0.2396683543920517\n",
      "1600/1429 \tLoss 0.42081382870674133\n",
      "1650/1429 \tLoss 0.36489224433898926\n",
      "1700/1429 \tLoss 0.36440011858940125\n",
      "1750/1429 \tLoss 0.3721810281276703\n",
      "1800/1429 \tLoss 0.32037264108657837\n",
      "1850/1429 \tLoss 0.4629383087158203\n",
      "1900/1429 \tLoss 0.26813754439353943\n",
      "1950/1429 \tLoss 0.35144537687301636\n",
      "2000/1429 \tLoss 0.30392855405807495\n",
      "2050/1429 \tLoss 0.4036408066749573\n",
      "2100/1429 \tLoss 0.40272408723831177\n",
      "2150/1429 \tLoss 0.35454151034355164\n",
      "2200/1429 \tLoss 0.31898945569992065\n",
      "2250/1429 \tLoss 0.24853308498859406\n",
      "2300/1429 \tLoss 0.2630567252635956\n",
      "2350/1429 \tLoss 0.3618282973766327\n",
      "2400/1429 \tLoss 0.3363146185874939\n",
      "2450/1429 \tLoss 0.33890682458877563\n",
      "2500/1429 \tLoss 0.4252641499042511\n",
      "2550/1429 \tLoss 0.4874011278152466\n",
      "2600/1429 \tLoss 0.28526729345321655\n",
      "2650/1429 \tLoss 0.26585790514945984\n",
      "2700/1429 \tLoss 0.3672539293766022\n",
      "2750/1429 \tLoss 0.2144288420677185\n",
      "2800/1429 \tLoss 0.3869645297527313\n",
      "2850/1429 \tLoss 0.4998960793018341\n",
      "Start Training\n",
      "2900/1429 \tLoss 0.2648463547229767\n",
      "2950/1429 \tLoss 0.3211454451084137\n",
      "3000/1429 \tLoss 0.31851476430892944\n",
      "3050/1429 \tLoss 0.3175424039363861\n",
      "3100/1429 \tLoss 0.3605774939060211\n",
      "3150/1429 \tLoss 0.2612077593803406\n",
      "3200/1429 \tLoss 0.3557760417461395\n",
      "3250/1429 \tLoss 0.2725076675415039\n",
      "3300/1429 \tLoss 0.3958289325237274\n",
      "3350/1429 \tLoss 0.40677160024642944\n",
      "3400/1429 \tLoss 0.31470879912376404\n",
      "3450/1429 \tLoss 0.2981523275375366\n",
      "3500/1429 \tLoss 0.26790717244148254\n",
      "3550/1429 \tLoss 0.24213755130767822\n",
      "3600/1429 \tLoss 0.36137744784355164\n",
      "3650/1429 \tLoss 0.2683207392692566\n",
      "3700/1429 \tLoss 0.27802592515945435\n",
      "3750/1429 \tLoss 0.35725128650665283\n",
      "3800/1429 \tLoss 0.2661597430706024\n",
      "3850/1429 \tLoss 0.2946529686450958\n",
      "3900/1429 \tLoss 0.34158051013946533\n",
      "3950/1429 \tLoss 0.5127559900283813\n",
      "4000/1429 \tLoss 0.36204037070274353\n",
      "4050/1429 \tLoss 0.38476940989494324\n",
      "4100/1429 \tLoss 0.28695914149284363\n",
      "4150/1429 \tLoss 0.2786502242088318\n",
      "4200/1429 \tLoss 0.3314061164855957\n",
      "4250/1429 \tLoss 0.26863086223602295\n",
      "Start Training\n",
      "4300/1429 \tLoss 0.3412710726261139\n",
      "4350/1429 \tLoss 0.36400607228279114\n",
      "4400/1429 \tLoss 0.3173750936985016\n",
      "4450/1429 \tLoss 0.45446357131004333\n",
      "4500/1429 \tLoss 0.23564207553863525\n",
      "4550/1429 \tLoss 0.32304927706718445\n",
      "4600/1429 \tLoss 0.29292917251586914\n",
      "4650/1429 \tLoss 0.28059402108192444\n",
      "4700/1429 \tLoss 0.3688073456287384\n",
      "4750/1429 \tLoss 0.296540766954422\n",
      "4800/1429 \tLoss 0.28415873646736145\n",
      "4850/1429 \tLoss 0.47755852341651917\n",
      "4900/1429 \tLoss 0.3050740361213684\n",
      "4950/1429 \tLoss 0.19782477617263794\n",
      "5000/1429 \tLoss 0.2738455533981323\n",
      "5050/1429 \tLoss 0.24229389429092407\n",
      "5100/1429 \tLoss 0.24101723730564117\n",
      "5150/1429 \tLoss 0.3167361617088318\n",
      "5200/1429 \tLoss 0.2777808606624603\n",
      "5250/1429 \tLoss 0.4107242226600647\n",
      "5300/1429 \tLoss 0.3361769914627075\n",
      "5350/1429 \tLoss 0.42485538125038147\n",
      "5400/1429 \tLoss 0.20546507835388184\n",
      "5450/1429 \tLoss 0.3554721176624298\n",
      "5500/1429 \tLoss 0.2718934118747711\n",
      "5550/1429 \tLoss 0.38552215695381165\n",
      "5600/1429 \tLoss 0.4042946994304657\n",
      "5650/1429 \tLoss 0.32480692863464355\n",
      "5700/1429 \tLoss 0.24591931700706482\n",
      "Start Training\n",
      "5750/1429 \tLoss 0.3163895905017853\n",
      "5800/1429 \tLoss 0.4018803834915161\n",
      "5850/1429 \tLoss 0.3384588956832886\n",
      "5900/1429 \tLoss 0.3768872916698456\n",
      "5950/1429 \tLoss 0.3296630382537842\n",
      "6000/1429 \tLoss 0.21737390756607056\n",
      "6050/1429 \tLoss 0.2892600893974304\n",
      "6100/1429 \tLoss 0.32499250769615173\n",
      "6150/1429 \tLoss 0.29920417070388794\n",
      "6200/1429 \tLoss 0.34733301401138306\n",
      "6250/1429 \tLoss 0.30915597081184387\n",
      "6300/1429 \tLoss 0.36481890082359314\n",
      "6350/1429 \tLoss 0.36570483446121216\n",
      "6400/1429 \tLoss 0.27275916934013367\n",
      "6450/1429 \tLoss 0.38298630714416504\n",
      "6500/1429 \tLoss 0.32721465826034546\n",
      "6550/1429 \tLoss 0.28031039237976074\n",
      "6600/1429 \tLoss 0.31825727224349976\n",
      "6650/1429 \tLoss 0.3143957853317261\n",
      "6700/1429 \tLoss 0.2742118537425995\n",
      "6750/1429 \tLoss 0.39723166823387146\n",
      "6800/1429 \tLoss 0.3449983298778534\n",
      "6850/1429 \tLoss 0.1758909374475479\n",
      "6900/1429 \tLoss 0.31465765833854675\n",
      "6950/1429 \tLoss 0.43782326579093933\n",
      "7000/1429 \tLoss 0.23885874450206757\n",
      "7050/1429 \tLoss 0.3475102484226227\n",
      "7100/1429 \tLoss 0.33735737204551697\n",
      "Start Training\n",
      "7150/1429 \tLoss 0.3698247969150543\n",
      "7200/1429 \tLoss 0.1492009460926056\n",
      "7250/1429 \tLoss 0.4271550476551056\n",
      "7300/1429 \tLoss 0.185180202126503\n",
      "7350/1429 \tLoss 0.3403952121734619\n",
      "7400/1429 \tLoss 0.27603381872177124\n",
      "7450/1429 \tLoss 0.3962588608264923\n",
      "7500/1429 \tLoss 0.24335910379886627\n",
      "7550/1429 \tLoss 0.38466838002204895\n",
      "7600/1429 \tLoss 0.41983696818351746\n",
      "7650/1429 \tLoss 0.30222946405410767\n",
      "7700/1429 \tLoss 0.33301857113838196\n",
      "7750/1429 \tLoss 0.45575714111328125\n",
      "7800/1429 \tLoss 0.40245822072029114\n",
      "7850/1429 \tLoss 0.3097311556339264\n",
      "7900/1429 \tLoss 0.3702457845211029\n",
      "7950/1429 \tLoss 0.38277140259742737\n",
      "8000/1429 \tLoss 0.2623922824859619\n",
      "8050/1429 \tLoss 0.26042690873146057\n",
      "8100/1429 \tLoss 0.5055909752845764\n",
      "8150/1429 \tLoss 0.3749135434627533\n",
      "8200/1429 \tLoss 0.3091442584991455\n",
      "8250/1429 \tLoss 0.28451764583587646\n",
      "8300/1429 \tLoss 0.37763333320617676\n",
      "8350/1429 \tLoss 0.42883267998695374\n",
      "8400/1429 \tLoss 0.3178376257419586\n",
      "8450/1429 \tLoss 0.23376698791980743\n",
      "8500/1429 \tLoss 0.2166932076215744\n",
      "8550/1429 \tLoss 0.39348796010017395\n",
      "Start Training\n",
      "8600/1429 \tLoss 0.21671061217784882\n",
      "8650/1429 \tLoss 0.29444006085395813\n",
      "8700/1429 \tLoss 0.29174789786338806\n",
      "8750/1429 \tLoss 0.3962076008319855\n",
      "8800/1429 \tLoss 0.2987995147705078\n",
      "8850/1429 \tLoss 0.3523359000682831\n",
      "8900/1429 \tLoss 0.2549944519996643\n",
      "8950/1429 \tLoss 0.24899132549762726\n",
      "9000/1429 \tLoss 0.2635342478752136\n",
      "9050/1429 \tLoss 0.22151583433151245\n",
      "9100/1429 \tLoss 0.36589401960372925\n",
      "9150/1429 \tLoss 0.34276512265205383\n",
      "9200/1429 \tLoss 0.3852003216743469\n",
      "9250/1429 \tLoss 0.3741096258163452\n",
      "9300/1429 \tLoss 0.37096306681632996\n",
      "9350/1429 \tLoss 0.33378779888153076\n",
      "9400/1429 \tLoss 0.26125410199165344\n",
      "9450/1429 \tLoss 0.37965792417526245\n",
      "9500/1429 \tLoss 0.360212504863739\n",
      "9550/1429 \tLoss 0.29119157791137695\n",
      "9600/1429 \tLoss 0.2742568552494049\n",
      "9650/1429 \tLoss 0.35769665241241455\n",
      "9700/1429 \tLoss 0.29731854796409607\n",
      "9750/1429 \tLoss 0.48284319043159485\n",
      "9800/1429 \tLoss 0.1883038580417633\n",
      "9850/1429 \tLoss 0.36117544770240784\n",
      "9900/1429 \tLoss 0.30471616983413696\n",
      "9950/1429 \tLoss 0.21967093646526337\n",
      "10000/1429 \tLoss 0.19058868288993835\n",
      "Start Training\n",
      "10050/1429 \tLoss 0.3525359034538269\n",
      "10100/1429 \tLoss 0.29093268513679504\n",
      "10150/1429 \tLoss 0.41843724250793457\n",
      "10200/1429 \tLoss 0.29521241784095764\n",
      "10250/1429 \tLoss 0.2884749174118042\n",
      "10300/1429 \tLoss 0.24885636568069458\n",
      "10350/1429 \tLoss 0.4030620753765106\n",
      "10400/1429 \tLoss 0.22909796237945557\n",
      "10450/1429 \tLoss 0.25928929448127747\n",
      "10500/1429 \tLoss 0.33848637342453003\n",
      "10550/1429 \tLoss 0.25123724341392517\n",
      "10600/1429 \tLoss 0.2424163818359375\n",
      "10650/1429 \tLoss 0.36113980412483215\n",
      "10700/1429 \tLoss 0.5124542117118835\n",
      "10750/1429 \tLoss 0.31223583221435547\n",
      "10800/1429 \tLoss 0.27682071924209595\n",
      "10850/1429 \tLoss 0.2706953287124634\n",
      "10900/1429 \tLoss 0.22602605819702148\n",
      "10950/1429 \tLoss 0.1937984824180603\n",
      "11000/1429 \tLoss 0.3841848373413086\n",
      "11050/1429 \tLoss 0.3210200369358063\n",
      "11100/1429 \tLoss 0.28432512283325195\n",
      "11150/1429 \tLoss 0.2555250823497772\n",
      "11200/1429 \tLoss 0.2931695580482483\n",
      "11250/1429 \tLoss 0.23538023233413696\n",
      "11300/1429 \tLoss 0.3993796408176422\n",
      "11350/1429 \tLoss 0.24437656998634338\n",
      "11400/1429 \tLoss 0.271699458360672\n",
      "Start Training\n",
      "11450/1429 \tLoss 0.3727301359176636\n",
      "11500/1429 \tLoss 0.25701430439949036\n",
      "11550/1429 \tLoss 0.26214489340782166\n",
      "11600/1429 \tLoss 0.19251741468906403\n",
      "11650/1429 \tLoss 0.402900367975235\n",
      "11700/1429 \tLoss 0.37405040860176086\n",
      "11750/1429 \tLoss 0.37427735328674316\n",
      "11800/1429 \tLoss 0.30831605195999146\n",
      "11850/1429 \tLoss 0.2920569181442261\n",
      "11900/1429 \tLoss 0.30853307247161865\n",
      "11950/1429 \tLoss 0.4039507210254669\n",
      "12000/1429 \tLoss 0.2762843668460846\n",
      "12050/1429 \tLoss 0.2821214199066162\n",
      "12100/1429 \tLoss 0.271586537361145\n",
      "12150/1429 \tLoss 0.28809425234794617\n",
      "12200/1429 \tLoss 0.3204575181007385\n",
      "12250/1429 \tLoss 0.2950778603553772\n",
      "12300/1429 \tLoss 0.42686742544174194\n",
      "12350/1429 \tLoss 0.3059089481830597\n",
      "12400/1429 \tLoss 0.25867462158203125\n",
      "12450/1429 \tLoss 0.303279310464859\n",
      "12500/1429 \tLoss 0.28523188829421997\n",
      "12550/1429 \tLoss 0.239736869931221\n",
      "12600/1429 \tLoss 0.20598618686199188\n",
      "12650/1429 \tLoss 0.2766471207141876\n",
      "12700/1429 \tLoss 0.20229092240333557\n",
      "12750/1429 \tLoss 0.2818225622177124\n",
      "12800/1429 \tLoss 0.4018571078777313\n",
      "12850/1429 \tLoss 0.352730929851532\n",
      "Start Training\n",
      "12900/1429 \tLoss 0.35130879282951355\n",
      "12950/1429 \tLoss 0.37558555603027344\n",
      "13000/1429 \tLoss 0.41386526823043823\n",
      "13050/1429 \tLoss 0.26669612526893616\n",
      "13100/1429 \tLoss 0.2620432674884796\n",
      "13150/1429 \tLoss 0.3654102385044098\n",
      "13200/1429 \tLoss 0.2573642432689667\n",
      "13250/1429 \tLoss 0.27096521854400635\n",
      "13300/1429 \tLoss 0.3072090148925781\n",
      "13350/1429 \tLoss 0.33952435851097107\n",
      "13400/1429 \tLoss 0.2297212928533554\n",
      "13450/1429 \tLoss 0.3435915410518646\n",
      " 41.85%\r"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    val_loss, y_pred, y_true = validate(val_loader, model, criterion)\n",
    "    validation_logs(i, val_loss, y_pred, y_true)\n",
    "    loss = train(\n",
    "                    train_loader,\n",
    "                    model,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    i,\n",
    "                    on_iteration=on_iteration_logs,\n",
    "                )\n",
    "    logger.add_scalar(\"Loss/Avg_Train\", loss, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, child in enumerate(model.children()):\n",
    "    if i > 6:\n",
    "        for p in child.parameters():\n",
    "            p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=TRAIN_SHUFFLE, num_workers=TRAIN_NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=INITIAL_LR*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,20):\n",
    "    val_loss, y_pred, y_true = validate(val_loader, model, criterion)\n",
    "    validation_logs(i, val_loss, y_pred, y_true)\n",
    "    loss = train(\n",
    "                    train_loader,\n",
    "                    model,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    i,\n",
    "                    on_iteration=on_iteration_logs,\n",
    "                )\n",
    "    logger.add_scalar(\"Loss/Avg_Train\", loss, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
