{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar, TensorboardLogger\n",
    "from ignite.contrib.handlers.tensorboard_logger import GradsHistHandler, GradsScalarHandler, OptimizerParamsHandler, OutputHandler, WeightsHistHandler, WeightsScalarHandler, global_step_from_engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Variables\n",
    "MEAN_PREPRO = [0.485, 0.456, 0.406]\n",
    "STD_PREPRO = [0.229, 0.224, 0.225]\n",
    "RESIZE_PREPRO = 256,256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "TRAIN_SHUFFLE = True\n",
    "TRAIN_NUM_WORKERS = 8\n",
    "TRAIN_PIN_MEMORY = True\n",
    "\n",
    "VAL_BATCH_SIZE = 1024\n",
    "VAL_SHUFFLE = False\n",
    "VAL_NUM_WORKERS = 8\n",
    "VAL_PIN_MEMORY = True\n",
    "\n",
    "N_CLASSES = 5\n",
    "\n",
    "INITIAL_LR = 1e-4\n",
    "DEVICE_ID = 1\n",
    "\n",
    "EARLY_STOPPING_PATIENCE=10\n",
    "\n",
    "MAX_EPOCHS = 30\n",
    "\n",
    "DATA_DIR = '/data/porn/data'\n",
    "TRAINSET_ROOT = f'{DATA_DIR}/train'\n",
    "TESTSET_ROOT = f'{DATA_DIR}/test'\n",
    "\n",
    "TENSORBOARD_DIR = '/data/porn/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=MEAN_PREPRO, std=STD_PREPRO\n",
    "    )\n",
    "prepro = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "prepro_val = transforms.Compose(\n",
    "    [transforms.Resize(RESIZE_PREPRO), transforms.ToTensor(), normalize]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 182535\n",
      "    Root location: /data/porn/data/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(256, 256), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['drawings', 'hentai', 'neutral', 'porn', 'sexy']\n"
     ]
    }
   ],
   "source": [
    "trainset = ImageFolder(TRAINSET_ROOT, transform=prepro)\n",
    "print(trainset)\n",
    "print(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 9187\n",
      "    Root location: /data/porn/data/test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(256, 256), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['drawings', 'hentai', 'neutral', 'porn', 'sexy']\n"
     ]
    }
   ],
   "source": [
    "valset = ImageFolder(TESTSET_ROOT, transform=prepro_val)\n",
    "print(valset)\n",
    "print(valset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=TRAIN_SHUFFLE, num_workers=TRAIN_NUM_WORKERS,pin_memory=TRAIN_PIN_MEMORY)\n",
    "val_loader = DataLoader(valset, batch_size=VAL_BATCH_SIZE, shuffle=VAL_SHUFFLE, num_workers=VAL_NUM_WORKERS,pin_memory=VAL_PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, N_CLASSES)\n",
    "device = f\"cuda:{DEVICE_ID}\"\n",
    "model = model.to(device)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers.param_scheduler import LRScheduler\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=INITIAL_LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "step_scheduler = MultiStepLR(optimizer, milestones=[10,20], gamma=0.5)\n",
    "scheduler = LRScheduler(step_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating trainer,evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, scheduler)\n",
    "metrics = {\n",
    "    'accuracy':Accuracy(),\n",
    "    'nll':Loss(criterion),\n",
    "    'cm':ConfusionMatrix(num_classes=5)\n",
    "}\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.RemovableEventHandle at 0x7fb5c7519dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['nll']\n",
    "    return -val_loss\n",
    "\n",
    "handler = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, score_function=score_function, trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED(every=50))\n",
    "def log_training_iteration(engine):\n",
    "    print(\"{} / {} : {}/{} - loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, engine.state.max_epochs, engine.state.iteration, engine.state.epoch_length, engine.state.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    val_evaluator.run(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@val_evaluator.on(Events.ITERATION_COMPLETED(every=50))\n",
    "def log_training_iteration(engine):\n",
    "    print(\"{} / {} : {}/{} - loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, engine.state.max_epochs, engine.state.iteration, engine.state.epoch_length, engine.state.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_confusion_matrix(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    cm = metrics['cm']\n",
    "    cm = cm.numpy()\n",
    "    cm = cm.astype(int)\n",
    "    classes = ['drawings', 'hentai', 'neutral', 'porn', 'sexy']\n",
    "    fig, ax = plt.subplots(figsize=(5,5))  \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax,fmt=\"d\")\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels') \n",
    "    ax.set_title('Confusion Matrix') \n",
    "    ax.xaxis.set_ticklabels(classes,rotation=90)\n",
    "    ax.yaxis.set_ticklabels(classes,rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.RemovableEventHandle at 0x7fb5c74a4390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('./saved_models', 'porn', n_saved=2, create_dir=True, save_as_state_dict=True, require_empty=False)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'model': model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorboardLogger(TENSORBOARD_DIR)\n",
    "logger.attach(\n",
    "    trainer,\n",
    "    log_handler=OutputHandler(tag=\"training\", metric_names=[\"accuracy\", \"nll\"]),\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    ")\n",
    "# Attach the logger to the trainer to log training loss at each iteration\n",
    "logger.attach(\n",
    "    trainer,\n",
    "    log_handler=OutputHandler(\n",
    "        tag=\"training\", output_transform=lambda l: {\"loss\": l}\n",
    "    ),\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    ")\n",
    "\n",
    "# Attach the logger to the trainer to log optimizer's parameters, e.g. learning rate at each iteration\n",
    "logger.attach(\n",
    "    trainer,\n",
    "    log_handler=OptimizerParamsHandler(optimizer),\n",
    "    event_name=Events.ITERATION_STARTED,\n",
    ")\n",
    "logger.attach(\n",
    "    train_evaluator,\n",
    "    log_handler=OutputHandler(\n",
    "        tag=\"trainval\",\n",
    "        metric_names=\"all\",\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    "    ),\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    ")\n",
    "logger.attach(\n",
    "    val_evaluator,\n",
    "        log_handler=OutputHandler(\n",
    "            tag=\"validation\",\n",
    "            metric_names=\"all\",\n",
    "            global_step_transform=global_step_from_engine(trainer),\n",
    "        ),\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5 : 50/714 - loss: 1.19\n",
      "1 / 5 : 100/714 - loss: 1.05\n",
      "1 / 5 : 150/714 - loss: 0.93\n",
      "1 / 5 : 200/714 - loss: 0.86\n",
      "1 / 5 : 250/714 - loss: 0.70\n",
      "1 / 5 : 300/714 - loss: 0.73\n",
      "1 / 5 : 350/714 - loss: 0.65\n",
      "1 / 5 : 400/714 - loss: 0.68\n",
      "1 / 5 : 450/714 - loss: 0.57\n",
      "1 / 5 : 500/714 - loss: 0.55\n",
      "1 / 5 : 550/714 - loss: 0.52\n",
      "1 / 5 : 600/714 - loss: 0.53\n",
      "1 / 5 : 650/714 - loss: 0.49\n",
      "1 / 5 : 700/714 - loss: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ignite/contrib/handlers/tensorboard_logger.py:120: UserWarning: TensorboardLogger output_handler can not log metrics value type <class 'torch.Tensor'>\n",
      "  \"metrics value type {}\".format(type(value)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 5 : 750/714 - loss: 0.53\n",
      "2 / 5 : 800/714 - loss: 0.50\n",
      "2 / 5 : 850/714 - loss: 0.39\n",
      "2 / 5 : 900/714 - loss: 0.46\n",
      "2 / 5 : 950/714 - loss: 0.47\n",
      "2 / 5 : 1000/714 - loss: 0.48\n",
      "2 / 5 : 1050/714 - loss: 0.40\n",
      "2 / 5 : 1100/714 - loss: 0.39\n",
      "2 / 5 : 1150/714 - loss: 0.42\n",
      "2 / 5 : 1200/714 - loss: 0.45\n",
      "2 / 5 : 1250/714 - loss: 0.48\n",
      "2 / 5 : 1300/714 - loss: 0.36\n",
      "2 / 5 : 1350/714 - loss: 0.34\n",
      "2 / 5 : 1400/714 - loss: 0.37\n",
      "3 / 5 : 1450/714 - loss: 0.44\n",
      "3 / 5 : 1500/714 - loss: 0.40\n",
      "3 / 5 : 1550/714 - loss: 0.40\n",
      "3 / 5 : 1600/714 - loss: 0.45\n"
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, child in enumerate(model.children()):\n",
    "    if i > 6:\n",
    "        for p in child.parameters():\n",
    "            p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=INITIAL_LR*0.25)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "step_scheduler = MultiStepLR(optimizer, milestones=[10,20], gamma=0.5)\n",
    "scheduler = LRScheduler(step_scheduler)\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, scheduler)\n",
    "metrics = {\n",
    "    'accuracy':Accuracy(),\n",
    "    'nll':Loss(criterion),\n",
    "    'cm':ConfusionMatrix(num_classes=5)\n",
    "}\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 4284\n",
       "\tepoch: 6\n",
       "\tepoch_length: 714\n",
       "\tmax_epochs: 6\n",
       "\toutput: 0.47826501727104187\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: 12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
