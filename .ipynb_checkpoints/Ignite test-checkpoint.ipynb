{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar, TensorboardLogger\n",
    "from ignite.contrib.handlers.tensorboard_logger import GradsHistHandler, GradsScalarHandler, OptimizerParamsHandler, OutputHandler, WeightsHistHandler, WeightsScalarHandler, global_step_from_engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Variables\n",
    "MEAN_PREPRO = [0.485, 0.456, 0.406]\n",
    "STD_PREPRO = [0.229, 0.224, 0.225]\n",
    "RESIZE_PREPRO = 350,350\n",
    "\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "TRAIN_SHUFFLE = True\n",
    "TRAIN_NUM_WORKERS = 0\n",
    "TRAIN_PIN_MEMORY = False\n",
    "\n",
    "VAL_BATCH_SIZE = 1024\n",
    "VAL_SHUFFLE = False\n",
    "VAL_NUM_WORKERS = 0\n",
    "VAL_PIN_MEMORY = False\n",
    "\n",
    "N_CLASSES = 5\n",
    "\n",
    "INITIAL_LR = 1e-4\n",
    "DEVICE_ID = 1\n",
    "\n",
    "EARLY_STOPPING_PATIENCE=10\n",
    "\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "DATA_DIR = '/home/jovyan/data-docker/datasets/porn/data'\n",
    "TRAINSET_ROOT = f'{DATA_DIR}/train'\n",
    "TESTSET_ROOT = f'{DATA_DIR}/test'\n",
    "\n",
    "TENSORBOARD_DIR = '/data/porn/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=MEAN_PREPRO, std=STD_PREPRO\n",
    "    )\n",
    "prepro = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "prepro_val = transforms.Compose(\n",
    "    [transforms.Resize(RESIZE_PREPRO), transforms.ToTensor(), normalize]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 182537\n",
      "    Root location: /home/jovyan/data-docker/datasets/porn/data/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(256, 256), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['drawings', 'hentai', 'neutral', 'porn', 'sexy']\n"
     ]
    }
   ],
   "source": [
    "trainset = ImageFolder(TRAINSET_ROOT, transform=prepro)\n",
    "print(trainset)\n",
    "print(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 9187\n",
      "    Root location: /home/jovyan/data-docker/datasets/porn/data/test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(350, 350), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['drawings', 'hentai', 'neutral', 'porn', 'sexy']\n"
     ]
    }
   ],
   "source": [
    "valset = ImageFolder(TESTSET_ROOT, transform=prepro_val)\n",
    "print(valset)\n",
    "print(valset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=TRAIN_SHUFFLE, num_workers=TRAIN_NUM_WORKERS,pin_memory=TRAIN_PIN_MEMORY)\n",
    "val_loader = DataLoader(valset, batch_size=VAL_BATCH_SIZE, shuffle=VAL_SHUFFLE, num_workers=VAL_NUM_WORKERS,pin_memory=VAL_PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving model to gpu if available\n",
    "device = f\"cuda:{DEVICE_ID}\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=INITIAL_LR)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating trainer,evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "metrics = {\n",
    "    'accuracy':Accuracy(),\n",
    "    'nll':Loss(criterion),\n",
    "    'cm':ConfusionMatrix(num_classes=5)\n",
    "}\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.attach(trainer, ['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.RemovableEventHandle at 0x7f4acc7b5610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['nll']\n",
    "    return -val_loss\n",
    "\n",
    "handler = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, score_function=score_function, trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    val_evaluator.run(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.RemovableEventHandle at 0x7f4acc7b5290>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('./saved_models', 'porn', n_saved=2, create_dir=True, save_as_state_dict=True, require_empty=False)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'model': model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db67d46d68464db6b0385a943d4d8a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=714.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with TensorboardLogger(TENSORBOARD_DIR) as logger: \n",
    "    logger.attach(\n",
    "        trainer,\n",
    "        log_handler=OutputHandler(tag=\"training\", metric_names=\"all\"),\n",
    "        event_name=Events.ITERATION_COMPLETED,\n",
    "    )\n",
    "    # Attach the logger to the trainer to log training loss at each iteration\n",
    "    logger.attach(\n",
    "        trainer,\n",
    "        log_handler=OutputHandler(\n",
    "            tag=\"training\", output_transform=lambda l: {\"loss\": l}\n",
    "        ),\n",
    "        event_name=Events.ITERATION_COMPLETED,\n",
    "    )\n",
    "    # Attach the logger to the trainer to log optimizer's parameters, e.g. learning rate at each iteration\n",
    "    logger.attach(\n",
    "        trainer,\n",
    "        log_handler=OptimizerParamsHandler(optimizer),\n",
    "        event_name=Events.ITERATION_STARTED,\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights norm after each iteration\n",
    "    logger.attach(\n",
    "        trainer,\n",
    "        log_handler=WeightsScalarHandler(model),\n",
    "        event_name=Events.ITERATION_COMPLETED,\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights as a histogram after each epoch\n",
    "    logger.attach(\n",
    "        trainer,\n",
    "        log_handler=WeightsHistHandler(model),\n",
    "        event_name=Events.EPOCH_COMPLETED,\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's gradients norm after each iteration\n",
    "    logger.attach(\n",
    "        trainer,\n",
    "        log_handler=GradsScalarHandler(model),\n",
    "        event_name=Events.ITERATION_COMPLETED,\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's gradients as a histogram after each epoch\n",
    "    logger.attach(\n",
    "        trainer, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED,\n",
    "    )\n",
    "    logger.attach(\n",
    "        train_evaluator,\n",
    "        log_handler=OutputHandler(\n",
    "            tag=\"trainval\",\n",
    "            metric_names=\"all\",\n",
    "            global_step_transform=global_step_from_engine(trainer),\n",
    "        ),\n",
    "        event_name=Events.EPOCH_COMPLETED,\n",
    "    )\n",
    "    logger.attach(\n",
    "        val_evaluator,\n",
    "            log_handler=OutputHandler(\n",
    "                tag=\"validation\",\n",
    "                metric_names=\"all\",\n",
    "                global_step_transform=global_step_from_engine(trainer),\n",
    "            ),\n",
    "        event_name=Events.EPOCH_COMPLETED,\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    trainer.run(train_loader, max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
